


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Jacobians, Hessians, hvp, vhp, and more: composing functorch transforms &mdash; functorch nightly documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/mystnb.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model ensembling" href="ensembling.html" />
    <link rel="prev" title="functorch.compile.ts_compile" href="../generated/functorch.compile.ts_compile.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch‚Äôs features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/functorch/versions.html'>nightly (1.14.0a0+git4648baa) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">functorch: Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Install functorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="whirlwind_tour.html">Whirlwind Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ux_limitations.html">UX Limitations</a></li>
</ul>
<p class="caption"><span class="caption-text">functorch API Reference and Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../functorch.html">functorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experimental.html">functorch.experimental</a></li>
<li class="toctree-l1"><a class="reference internal" href="../aot_autograd.html">functorch.compile (experimental)</a></li>
</ul>
<p class="caption"><span class="caption-text">functorch Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Jacobians, Hessians, hvp, vhp, and more: composing functorch transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensembling.html">Model ensembling</a></li>
<li class="toctree-l1"><a class="reference internal" href="per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural_tangent_kernels.html">Neural Tangent Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="aot_autograd_optimizations.html">AOT Autograd - How to use and optimize?</a></li>
<li class="toctree-l1"><a class="reference internal" href="minifier.html">Using the Minifier</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Jacobians, Hessians, hvp, vhp, and more: composing functorch transforms</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/jacobians_hessians.ipynb.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="tex2jax_ignore mathjax_ignore section" id="jacobians-hessians-hvp-vhp-and-more-composing-functorch-transforms">
<h1>Jacobians, Hessians, hvp, vhp, and more: composing functorch transforms<a class="headerlink" href="#jacobians-hessians-hvp-vhp-and-more-composing-functorch-transforms" title="Permalink to this headline">¬∂</a></h1>
<a href="https://colab.research.google.com/github/pytorch/pytorch/blob/master/functorch/notebooks/jacobians_hessians.ipynb">
  <img style="width: auto" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
<p>Computing jacobians or hessians are useful in a number of non-traditional
deep learning models. It is difficult (or annoying) to compute these quantities
efficiently using a standard autodiff system like PyTorch Autograd; functorch
provides ways of computing various higher-order autodiff quantities efficiently.</p>
<div class="section" id="computing-the-jacobian">
<h2>Computing the Jacobian<a class="headerlink" href="#computing-the-jacobian" title="Permalink to this headline">¬∂</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs start with a function that we‚Äôd like to compute the jacobian of.  This is a simple linear function with non-linear activation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs add some dummy data:   a weight, a bias, and a feature vector x.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">D</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">)</span> <span class="c1"># feature vector</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs think of <code class="docutils literal notranslate"><span class="pre">predict</span></code> as a function that maps the input <code class="docutils literal notranslate"><span class="pre">x</span></code> from <span class="math notranslate nohighlight">\(R^D -&gt; R^D\)</span>.
PyTorch Autograd computes vector-Jacobian products. In order to compute the full
Jacobian of this <span class="math notranslate nohighlight">\(R^D -&gt; R^D\)</span> function, we would have to compute it row-by-row
by using a different unit vector each time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_jac</span><span class="p">(</span><span class="n">xp</span><span class="p">):</span>
    <span class="n">jacobian_rows</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">xp</span><span class="p">),</span> <span class="n">xp</span><span class="p">,</span> <span class="n">vec</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                     <span class="k">for</span> <span class="n">vec</span> <span class="ow">in</span> <span class="n">unit_vectors</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">jacobian_rows</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xp</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="n">unit_vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>

<span class="n">jacobian</span> <span class="o">=</span> <span class="n">compute_jac</span><span class="p">(</span><span class="n">xp</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">jacobian</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">jacobian</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># show first row</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([16, 16])
tensor([-0.5956, -0.6096, -0.1326, -0.2295,  0.4490,  0.3661, -0.1672, -1.1190,
         0.1705, -0.6683,  0.1851,  0.1630,  0.0634,  0.6547,  0.5908, -0.1308])
</pre></div>
</div>
</div>
</div>
<p>Instead of computing the jacobian row-by-row, we can use vmap to get rid of the for-loop and vectorize the computation.
We can‚Äôt directly apply vmap to PyTorch Autograd; instead, functorch provides a vjp transform:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functorch</span> <span class="kn">import</span> <span class="n">vmap</span><span class="p">,</span> <span class="n">vjp</span>

<span class="n">_</span><span class="p">,</span> <span class="n">vjp_fn</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>

<span class="n">ft_jacobian</span><span class="p">,</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">vjp_fn</span><span class="p">)(</span><span class="n">unit_vectors</span><span class="p">)</span>

<span class="c1"># lets confirm both methods compute the same result</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ft_jacobian</span><span class="p">,</span> <span class="n">jacobian</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In future tutorial a composition of reverse-mode AD and vmap will give us per-sample-gradients.
In this tutorial, composing reverse-mode AD and vmap gives us Jacobian computation!
Various compositions of vmap and autodiff transforms can give us different interesting quantities.</p>
<p>functorch provides <strong>jacrev</strong> as a convenience function that performs the vmap-vjp composition to compute jacobians. <strong>jacrev</strong> accepts an argnums argument that says which argument we would like to compute Jacobians with respect to.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functorch</span> <span class="kn">import</span> <span class="n">jacrev</span>

<span class="n">ft_jacobian</span> <span class="o">=</span> <span class="n">jacrev</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="c1"># confirm </span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ft_jacobian</span><span class="p">,</span> <span class="n">jacobian</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs compare the performance of the two ways to compute the jacobian. The functorch version is much faster (and becomes even faster the more outputs there are).</p>
<p>In general, we expect that vectorization via vmap can help eliminate overhead and give better utilization of your hardware.</p>
<p>Vmap does this magic by pushing the outer loop down into the functions primitive operations in order to obtain better performance.</p>
<p>Let‚Äôs make a quick function to evaluate performance and deal with microseconds and milliseconds measurements:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_perf</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">first_descriptor</span><span class="p">,</span> <span class="n">second</span><span class="p">,</span> <span class="n">second_descriptor</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;  takes torch.benchmark objects and compares delta of second vs first. &quot;&quot;&quot;</span>
  <span class="n">faster</span> <span class="o">=</span> <span class="n">second</span><span class="o">.</span><span class="n">times</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">slower</span> <span class="o">=</span> <span class="n">first</span><span class="o">.</span><span class="n">times</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">gain</span> <span class="o">=</span> <span class="p">(</span><span class="n">slower</span><span class="o">-</span><span class="n">faster</span><span class="p">)</span><span class="o">/</span><span class="n">slower</span>
  <span class="k">if</span> <span class="n">gain</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">gain</span> <span class="o">*=-</span><span class="mi">1</span> 
  <span class="n">final_gain</span> <span class="o">=</span> <span class="n">gain</span><span class="o">*</span><span class="mi">100</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Performance delta: </span><span class="si">{</span><span class="n">final_gain</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> percent improvement with </span><span class="si">{</span><span class="n">second_descriptor</span><span class="si">}</span><span class="s2"> &quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And then run the performance comparison:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.benchmark</span> <span class="kn">import</span> <span class="n">Timer</span>

<span class="n">without_vmap</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">(</span><span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;compute_jac(xp)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="nb">globals</span><span class="p">())</span>
<span class="n">with_vmap</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">(</span><span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;jacrev(predict, argnums=2)(weight, bias, x)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="nb">globals</span><span class="p">())</span>

<span class="n">no_vmap_timer</span> <span class="o">=</span> <span class="n">without_vmap</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
<span class="n">with_vmap_timer</span> <span class="o">=</span> <span class="n">with_vmap</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">no_vmap_timer</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">with_vmap_timer</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;torch.utils.benchmark.utils.common.Measurement object at 0x7fa9a911b350&gt;
compute_jac(xp)
  2.25 ms
  1 measurement, 500 runs , 1 thread
&lt;torch.utils.benchmark.utils.common.Measurement object at 0x7fa9a6a99d50&gt;
jacrev(predict, argnums=2)(weight, bias, x)
  884.34 us
  1 measurement, 500 runs , 1 thread
</pre></div>
</div>
</div>
</div>
<p>Lets do a relative performance comparison of the above with our get_perf function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_perf</span><span class="p">(</span><span class="n">no_vmap_timer</span><span class="p">,</span> <span class="s2">&quot;without vmap&quot;</span><span class="p">,</span>  <span class="n">with_vmap_timer</span><span class="p">,</span> <span class="s2">&quot;vmap&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Performance delta: 60.7170 percent improvement with vmap 
</pre></div>
</div>
</div>
</div>
<p>Furthemore, it‚Äôs pretty easy to flip the problem around and say we want to compute Jacobians of the parameters to our model (weight, bias) instead of the input.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># note the change in input via argnums params of 0,1 to map to weight and bias</span>
<span class="n">ft_jac_weight</span><span class="p">,</span> <span class="n">ft_jac_bias</span> <span class="o">=</span> <span class="n">jacrev</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="reverse-mode-jacobian-jacrev-vs-forward-mode-jacobian-jacfwd">
<h2>reverse-mode Jacobian (jacrev) vs forward-mode Jacobian (jacfwd)<a class="headerlink" href="#reverse-mode-jacobian-jacrev-vs-forward-mode-jacobian-jacfwd" title="Permalink to this headline">¬∂</a></h2>
<p>We offer two APIs to compute jacobians: <strong>jacrev</strong> and <strong>jacfwd</strong>:</p>
<ul class="simple">
<li><p>jacrev uses reverse-mode AD. As you saw above it is a composition of our vjp and vmap transforms.</p></li>
<li><p>jacfwd uses forward-mode AD. It is implemented as a composition of our jvp and vmap transforms.</p></li>
</ul>
<p>jacfwd and jacrev can be substituted for each other but they have different performance characteristics.</p>
<p>As a general rule of thumb, if you‚Äôre computing the jacobian of an <span class="math notranslate nohighlight">\(ùëÖ^N \to R^M\)</span> function, and there are many more outputs than inputs (i.e. <span class="math notranslate nohighlight">\(M &gt; N\)</span>) then jacfwd is preferred, otherwise use jacrev. There are exceptions to this rule, but a non-rigorous argument for this follows:</p>
<p>In reverse-mode AD, we are computing the jacobian row-by-row, while in forward-mode AD (which computes Jacobian-vector products), we are computing it column-by-column. The Jacobian matrix has M rows and N columns, so if it is taller or wider one way we may prefer the method that deals with fewer rows or columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functorch</span> <span class="kn">import</span> <span class="n">jacrev</span><span class="p">,</span> <span class="n">jacfwd</span>
</pre></div>
</div>
</div>
</div>
<p>First, let‚Äôs benchmark with more inputs than outputs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Din</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">Dout</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Dout</span><span class="p">,</span> <span class="n">Din</span><span class="p">)</span>

<span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Dout</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Din</span><span class="p">)</span>

<span class="c1"># remember the general rule about taller vs wider...here we have a taller matrix:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">using_fwd</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">(</span><span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;jacfwd(predict, argnums=2)(weight, bias, x)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="nb">globals</span><span class="p">())</span>
<span class="n">using_bwd</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">(</span><span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;jacrev(predict, argnums=2)(weight, bias, x)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="nb">globals</span><span class="p">())</span>

<span class="n">jacfwd_timing</span> <span class="o">=</span> <span class="n">using_fwd</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
<span class="n">jacrev_timing</span> <span class="o">=</span> <span class="n">using_bwd</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;jacfwd time: </span><span class="si">{</span><span class="n">jacfwd_timing</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;jacrev time: </span><span class="si">{</span><span class="n">jacrev_timing</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2048, 32])
jacfwd time: &lt;torch.utils.benchmark.utils.common.Measurement object at 0x7fa9a5d792d0&gt;
jacfwd(predict, argnums=2)(weight, bias, x)
  1.32 ms
  1 measurement, 500 runs , 1 thread
jacrev time: &lt;torch.utils.benchmark.utils.common.Measurement object at 0x7fa9a4dee450&gt;
jacrev(predict, argnums=2)(weight, bias, x)
  12.46 ms
  1 measurement, 500 runs , 1 thread
</pre></div>
</div>
</div>
</div>
<p>and then do a relative benchmark:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_perf</span><span class="p">(</span><span class="n">jacfwd_timing</span><span class="p">,</span> <span class="s2">&quot;jacfwd&quot;</span><span class="p">,</span> <span class="n">jacrev_timing</span><span class="p">,</span> <span class="s2">&quot;jacrev&quot;</span><span class="p">,</span> <span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Performance delta: 842.8274 percent improvement with jacrev 
</pre></div>
</div>
</div>
</div>
<p>and now the reverse - more outputs (M) than inputs (N):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Din</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">Dout</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Dout</span><span class="p">,</span> <span class="n">Din</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Dout</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Din</span><span class="p">)</span>

<span class="n">using_fwd</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">(</span><span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;jacfwd(predict, argnums=2)(weight, bias, x)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="nb">globals</span><span class="p">())</span>
<span class="n">using_bwd</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">(</span><span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;jacrev(predict, argnums=2)(weight, bias, x)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="nb">globals</span><span class="p">())</span>

<span class="n">jacfwd_timing</span> <span class="o">=</span> <span class="n">using_fwd</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
<span class="n">jacrev_timing</span> <span class="o">=</span> <span class="n">using_bwd</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;jacfwd time: </span><span class="si">{</span><span class="n">jacfwd_timing</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;jacrev time: </span><span class="si">{</span><span class="n">jacrev_timing</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>jacfwd time: &lt;torch.utils.benchmark.utils.common.Measurement object at 0x7fa9a5d64790&gt;
jacfwd(predict, argnums=2)(weight, bias, x)
  7.99 ms
  1 measurement, 500 runs , 1 thread
jacrev time: &lt;torch.utils.benchmark.utils.common.Measurement object at 0x7fa9a5d67b50&gt;
jacrev(predict, argnums=2)(weight, bias, x)
  1.09 ms
  1 measurement, 500 runs , 1 thread
</pre></div>
</div>
</div>
</div>
<p>and a relative perf comparison:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_perf</span><span class="p">(</span><span class="n">jacrev_timing</span><span class="p">,</span> <span class="s2">&quot;jacrev&quot;</span><span class="p">,</span> <span class="n">jacfwd_timing</span><span class="p">,</span> <span class="s2">&quot;jacfwd&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Performance delta: 635.2095 percent improvement with jacfwd 
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="hessian-computation-with-functorch-hessian">
<h2>Hessian computation with functorch.hessian<a class="headerlink" href="#hessian-computation-with-functorch-hessian" title="Permalink to this headline">¬∂</a></h2>
<p>We offer a convenience API to compute hessians: <code class="docutils literal notranslate"><span class="pre">functorch.hessian</span></code>.
Hessians are the jacobian of the jacobian (or the partial derivative of the partial derivative, aka second order).</p>
<p>This suggests that one can just compose functorch‚Äôs jacobian transforms to compute the Hessian.
Indeed, under the hood, <code class="docutils literal notranslate"><span class="pre">hessian(f)</span></code> is simply <code class="docutils literal notranslate"><span class="pre">jacfwd(jacrev(f))</span></code>.</p>
<p>Note: to boost performance: depending on your model, you may also want to use <code class="docutils literal notranslate"><span class="pre">jacfwd(jacfwd(f))</span></code> or <code class="docutils literal notranslate"><span class="pre">jacrev(jacrev(f))</span></code> instead to compute hessians leveraging the rule of thumb above regarding wider vs taller matrices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functorch</span> <span class="kn">import</span> <span class="n">hessian</span>

<span class="c1"># lets reduce the size in order not to blow out colab. Hessians require significant memory:</span>
<span class="n">Din</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">Dout</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Dout</span><span class="p">,</span> <span class="n">Din</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Dout</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Din</span><span class="p">)</span>

<span class="n">hess_api</span> <span class="o">=</span> <span class="n">hessian</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">hess_fwdfwd</span> <span class="o">=</span> <span class="n">jacfwd</span><span class="p">(</span><span class="n">jacfwd</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="c1">#hess_revrev = jacrev(jacrev(predict, argnums=2), argnums=2)(weight, bias, x)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs verify we have the same result regardless of using hessian api or using jacfwd(jacfwd())</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">hess_api</span><span class="p">,</span> <span class="n">hess_fwdfwd</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="batch-jacobian-and-batch-hessian">
<h2>Batch Jacobian and Batch Hessian<a class="headerlink" href="#batch-jacobian-and-batch-hessian" title="Permalink to this headline">¬∂</a></h2>
<p>In the above examples we‚Äôve been operating with a single feature vector. In some cases you might want to take the Jacobian of a batch of outputs with respect to a batch of inputs. That is, given a batch of inputs of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">N)</span></code> and a function that goes from <span class="math notranslate nohighlight">\(R^N \to R^M\)</span>, we would like a Jacobian of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">M,</span> <span class="pre">N)</span></code>.</p>
<p>The easiest way to do this is to use vmap:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">Din</span> <span class="o">=</span> <span class="mi">31</span>
<span class="n">Dout</span> <span class="o">=</span> <span class="mi">33</span>

<span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Dout</span><span class="p">,</span> <span class="n">Din</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;weight shape = </span><span class="si">{</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Dout</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">Din</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>weight shape = torch.Size([33, 31])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compute_batch_jacobian</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">jacrev</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">in_dims</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">batch_jacobian0</span> <span class="o">=</span> <span class="n">compute_batch_jacobian</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If you have a function that goes from (B, N) -&gt; (B, M) instead and are certain that each input produces an independent output, then it‚Äôs also sometimes possible to do this without using vmap by summing the outputs and then computing the Jacobian of that function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_with_output_summed</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">predict</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">batch_jacobian1</span> <span class="o">=</span> <span class="n">jacrev</span><span class="p">(</span><span class="n">predict_with_output_summed</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">movedim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">batch_jacobian0</span><span class="p">,</span> <span class="n">batch_jacobian1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If you instead have a function that goes from <span class="math notranslate nohighlight">\(ùëÖ^ùëÅ \to ùëÖ^ùëÄ\)</span> but inputs that are batched, you compose vmap with jacrev to compute batched jacobians:</p>
<p>Finally, batch hessians can be computed similarly. It‚Äôs easiest to think about them by using vmap to batch over hessian computation, but in some cases the sum trick also works.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compute_batch_hessian</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">hessian</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">in_dims</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

<span class="n">batch_hess</span> <span class="o">=</span> <span class="n">compute_batch_hessian</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">batch_hess</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([64, 33, 31, 31])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="computing-hessian-vector-products">
<h2>Computing Hessian-vector products<a class="headerlink" href="#computing-hessian-vector-products" title="Permalink to this headline">¬∂</a></h2>
<p>The naive way to compute a Hessian-vector product (hvp) is to materialize the full Hessian and perform a dot-product with a vector. We can do better: it turns out we don‚Äôt need to materialize the full Hessian to do this. We‚Äôll go through two (of many) different strategies to compute Hessian-vector products:</p>
<ul class="simple">
<li><p>composing reverse-mode AD with reverse-mode AD</p></li>
<li><p>composing reverse-mode AD with forward-mode AD</p></li>
</ul>
<p>Composing reverse-mode AD with forward-mode AD (as opposed to reverse-mode with reverse-mode) is generally the more memory efficient way to compute a hvp because forward-mode AD doesn‚Äôt need to construct an Autograd graph and save intermediates for backward:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functorch</span> <span class="kn">import</span> <span class="n">jvp</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">vjp</span>

<span class="k">def</span> <span class="nf">hvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jvp</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Here‚Äôs some sample usage.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">sin</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2048</span><span class="p">)</span>
<span class="n">tangent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2048</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">hvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="p">(</span><span class="n">tangent</span><span class="p">,))</span>
</pre></div>
</div>
</div>
</div>
<p>If PyTorch forward-AD does not have coverage for your operations, then we can instead compose reverse-mode AD with reverse-mode AD:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hvp_revrev</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">vjp_fn</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="o">*</span><span class="n">primals</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">vjp_fn</span><span class="p">(</span><span class="o">*</span><span class="n">tangents</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result_hvp_revrev</span> <span class="o">=</span> <span class="n">hvp_revrev</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="p">(</span><span class="n">tangent</span><span class="p">,))</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">result_hvp_revrev</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="ensembling.html" class="btn btn-neutral float-right" title="Model ensembling" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="../generated/functorch.compile.ts_compile.html" class="btn btn-neutral" title="functorch.compile.ts_compile" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Jacobians, Hessians, hvp, vhp, and more: composing functorch transforms</a><ul>
<li><a class="reference internal" href="#computing-the-jacobian">Computing the Jacobian</a></li>
<li><a class="reference internal" href="#reverse-mode-jacobian-jacrev-vs-forward-mode-jacobian-jacfwd">reverse-mode Jacobian (jacrev) vs forward-mode Jacobian (jacfwd)</a></li>
<li><a class="reference internal" href="#hessian-computation-with-functorch-hessian">Hessian computation with functorch.hessian</a></li>
<li><a class="reference internal" href="#batch-jacobian-and-batch-hessian">Batch Jacobian and Batch Hessian</a></li>
<li><a class="reference internal" href="#computing-hessian-vector-products">Computing Hessian-vector products</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script >let toggleHintShow = 'Click to show';</script>
         <script >let toggleHintHide = 'Click to hide';</script>
         <script >let toggleOpenOnPrint = 'true';</script>
         <script src="../_static/togglebutton.js"></script>
         <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
         <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
         <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>¬© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook‚Äôs Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>